{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO4+fsUtvJxlGl/WpHvKEDs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ajitakarkee/Natural-Language-Processing-NLP-/blob/main/Class_lab%5BText_classification%5D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Lab second: Text Classification"
      ],
      "metadata": {
        "id": "AFJKfoO3eDR8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "RVlBh_L6d8am"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = {\n",
        "    'text': [\n",
        "        \"Congratulations! You won a lottery prize\",\n",
        "        \"Call this number to claim your reward\",\n",
        "        \"Let's meet for lunch tomorrow\",\n",
        "        \"Are you coming to the office today?\",\n",
        "        \"Free entry in a weekly competition\",\n",
        "        \"Can we schedule a meeting?\"\n",
        "    ]\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 2: Text Preprocessing (Cleaning & Normalization)"
      ],
      "metadata": {
        "id": "-TFOPaCles1T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "df['clean_text'] = df['text'].apply(clean_text)\n",
        "print(df[['text','clean_text']])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCH2wASeescx",
        "outputId": "83e26fd0-bfcf-49a9-98e3-242e9237c07d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                       text  \\\n",
            "0  Congratulations! You won a lottery prize   \n",
            "1     Call this number to claim your reward   \n",
            "2             Let's meet for lunch tomorrow   \n",
            "3       Are you coming to the office today?   \n",
            "4        Free entry in a weekly competition   \n",
            "5                Can we schedule a meeting?   \n",
            "\n",
            "                                clean_text  \n",
            "0  congratulations you won a lottery prize  \n",
            "1    call this number to claim your reward  \n",
            "2             lets meet for lunch tomorrow  \n",
            "3       are you coming to the office today  \n",
            "4       free entry in a weekly competition  \n",
            "5                can we schedule a meeting  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 3: Train-Test Split"
      ],
      "metadata": {
        "id": "j4VPzU-IfO0r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Adding a 'label' column for text classification based on common spam/ham patterns\n",
        "df['label'] = [1, 1, 0, 0, 1, 0] # Assuming 1 for spam, 0 for not spam\n",
        "\n",
        "X = df['clean_text']\n",
        "y = df['label']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "print(\"Training samples:\", len(X_train))\n",
        "print(\"Testing samples:\", len(X_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5TA_qZ_4fQy9",
        "outputId": "9bffe614-d275-4331-cf44-0c7e7df3c78b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training samples: 4\n",
            "Testing samples: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 4: Convert Text to Numerical Features (TF-IDF)"
      ],
      "metadata": {
        "id": "_FcjDhmQfdiN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = vectorizer.transform(X_test)\n",
        "\n",
        "print(\"Feature names:\", vectorizer.get_feature_names_out())\n",
        "print(\"Training TF-IDF shape:\", X_train_tfidf.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jB94qMT8fhAd",
        "outputId": "3e40742e-9c5a-4312-f0d5-2d3fa3762dab"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature names: ['are' 'can' 'coming' 'competition' 'entry' 'for' 'free' 'in' 'lets'\n",
            " 'lunch' 'meet' 'meeting' 'office' 'schedule' 'the' 'to' 'today'\n",
            " 'tomorrow' 'we' 'weekly' 'you']\n",
            "Training TF-IDF shape: (4, 21)\n"
          ]
        }
      ]
    }
  ]
}